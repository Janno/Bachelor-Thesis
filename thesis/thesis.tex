\documentclass[11pt,a4paper,oneside]{book}

\input{includes.tex}
\input{macros.tex}


\title{Constructive Formalization of Regular Languages}
\author{Jan-Oliver Kaiser}

\begin{document}
    \maketitle

    \chapter*{Abstract}
    Existing formalizations of regular languages in constructive settings are mostly limited to regular expressions and finite automata. 
    Furthermore, these usually require in the order of 10,000 lines of code.\todo{Citations?} %
    The goal of this thesis is to show that an extensive, yet elegant formalization of regular languages can be achieved in constructive type theory. 
    In addition to regular expressions and finite automata, our formalization includes the Myhill-Nerode theorem. 
    The entire development weighs in at approximately 3,300 lines of code.\todo{Reduce \& update} %

    %\chapter*{Acknowledgements}

    \tableofcontents
    


    \chapter{Introduction}

        \paragraph{} 
            Regular languages are a well-studied class of formal languages. 
            \todo{History}
            \todo{Theoretical importance}
            \todo{Practical importance?}
            We will prove the equivalence of three well-known characterizations of regular languages: regular expressions, finite automata and the characterization given by Myhill-Nerode theorem.

        \section{Recent work}
        
            \paragraph{} 
                There have been many publications on regular languages in recent years. Many of them investigate decidability of equivalence of regular languages, though there have also been new equivalence proofs regarding different characterizations of regular languages.

    \chapter{Coq, \ssreflect}

        \paragraph{}
            We decided to employ the Small Scale Reflection Extension (\textbf{\ssreflect}) for the \textbf{\coq} proof assistant. 
            The most important factors in this decision were \ssreflect's excellent support for finite types, list operations and graphs. \ssreflect{} also introduces many syntactic extensions that can often be used to shorten the bookkeeping overhead of proofs considerably.

    \chapter{Decidable Languages}

    \section{Definition}
        \paragraph{}
        We closely follow the definitions from \cite{DBLP:books/daglib/0011126}.
        An \textbf{alphabet} $\Sigma$ is a finite, nonempty set of symbols. 
        A \textbf{word} $w$ is a finite sequence of symbols chosen from some alphabet. 
        We use $|w|$ to denote the \textbf{length} of a word $w$. 
        We define $\Sigma^k$ to be the \textbf{set of words of length k}.
        The \textbf{set of all words} over an alphabet $\Sigma$ is denoted $\Sigma^*$, i.e.,$\Sigma^* = \bigcup_{k \in \mathbb{N}} \Sigma^k$.
        
        \paragraph{} We restrict all further discussion to \textbf{decidable languages}:
        \[
            \mathcal{L}_{dec} := \{ \, L \, \subseteq \, \Sigma^* \, 
                \vert \, \exists f. \, \forall x \in \Sigma^*. \, f(x) = 1 \Leftrightarrow  x \in L. \}
        \] 

        \paragraph{} 
            We employ finite types to formalize alphabets \todo{nonemptiness}. 
            Words are formalized as sequences over the alphabet.
            Decidable languages are represented by functions from $word$ to $bool$.
            \code{language}{}{misc_char}
            \code{language}{}{misc_word}
            \code{language}{}{misc_language}

        \subsection{Operators}
            \todo{Define Kleene star}%
            The following operations will be used on languages: Kleene star, concatenation ($L_1 \cdot L_2 := \{w \cdot v\ \vert w \in L_1,  \in L_2\}$), and the boolean operations ($\cup$, $\cap$, $\neg$) on languages.

            \paragraph{}
                We take Coquand and Siles' implementation of the operators.

                \code{lang_conc}{}{regexp_conc}
                %\vspace{-0.4cm}

                \todo{Move def. of residual up from 3.2.2}
                \code{lang_star}{}{regexp_star}
                \vspace{-0.4cm}
                \code{lang_plus}{}{regexp_plus}
                \vspace{-0.4cm}
                \code{lang_prod}{}{regexp_prod}
                \vspace{-0.4cm}
                \code{lang_compl}{}{regexp_compl}
                \todo{Explain names}
                \todo{Find a consistent ordering}

            \begin{theorem}{}
                \label{DecLangClosed}
                The decidable languages are closed under concatenation, Kleene star, union, intersection and negation. 
            \end{theorem}
            \begin{proof}
                For concatenation and the Kleene star, the validity of this claim is easily seen by considering nonempty substrings, of which there are finitely many. 
                The boolean operations can be applied directly to the decision functions.
            \end{proof}

            \paragraph{}
                We have already given decision algorithms for every operator. 
                It remains to show that they are correct.
                 



                



        \section{Regular Languages}
        
    
            %\paragraph{}
            \begin{definition}{}
                \label{REG}
            The set of regular languages $REG$ is defined to be exactly those languages generated by the following inductive definition.
            \begin{itemize}
                \item
                    $\emptyset \in REG$, 
                \item
                    $\forall a \in \Sigma. \, \{a\} \in REG$, 
                \item
                    $\forall L_1, L_2 \in REG. \, L_1^* \in REG, \, L_1 \cup L_2 \in REG, \, L_1 \cdot L_2 \in REG$.
            \end{itemize}
            \end{definition}


            \subsection{Regular Expressions}

                \paragraph{} 
                    Regular expressions mirror the definition of regular languages very closely. 
                    We will consider \textbf{extended regular expressions} that include negation ($Not$), intersection ($And$) and $.$ ($Dot$), which is a single-symbol wildcard. 
                    We take the implementation from Coquand and Siles's development (\cite{DBLP:conf/cpp/CoquandS11}), which is also based on \ssreflect\ and comes with helpful infrastructure for our proofs.

                \code{regexp}{Regular Expressions}{regexp_regular_expression}

                \todo{Standard regular expressions, boolean predicate}

                \paragraph{}
                We will later prove that this definition is equivalent to the inductive definition of regular languages in \ref{REG}.
                In order to do that, we introduce a predicate on regular expressions that distinguishes \textbf{standard regular expressions} 
                from \textbf{extended regular expressions} (as introduced above).
                Standard regular expression consist only of $Void$, $Eps$, $Atom$, $Star$ and $Plus$.

                \code{re_standard}{}{re_standard_standard}

                \todo{Connect standard regexp to reg. languages}
                 

            \subsection{Deciding Language Membership}
                    \paragraph{}
                        We make use of \textbf{derivatives of regular expressions} (\cite{DBLP:journals/jacm/Brzozowski64}) to decide if a word $w \in \Sigma^*$ is contained in the language $\lang{r}$ of the regular expression $r$. 
                        Derivatives are themselves regular expressions and are computed with respect to a single input character. 
                        In order to define derivatives, we first define a related concept.

                    \begin{definition}{}
                        \label{residual}
                        The residual of a regular expression w.r.t to a character $a$ is the set of words $w$ such that $a \cdot w \in L$.
                        \code{regexp_resiual}{}{regexp_residual}
                    \end{definition}

                    \begin{definition}{}
                        \label{residual}
                        The derivative $der \,  a \, r$ of $r$ w.r.t. to $a$ is defined such that 
                        \[
                            \forall w \in \Sigma^*. \, w \, \in \, \lang{der \, a \, r} \Leftrightarrow w \, \in \, residual \, a \, \lang{r}.
                        \]
                    \end{definition}

                    \paragraph{}
                        A suitable implementation is provided by Coquand and Siles.

                    \code{regexp_der}{Derivatives of Regular Expressions}{regexp_der}


                    \begin{theorem}
                        \label{der_correct}
                        For all $r$, $w$ and $a$, we have that $w \in der \, a \, r$ if and only if $w \in residual \, a $.
                    \end{theorem}

                    \begin{proof}
                        We prove the claim by induction over $r$. Two cases are non-trivial: 
%                        \begin{enumerate}
%                            \item
%                                $der \, a \, (Conc \, r_1 \, r_2)$: 
%                                We have to check if $r_1$ accepts the empty word. 
%                                If it does not, the derivative is $Conc \, (der \, a \, r_1) \, r_2$.
%                                If it does, we also have to consider the case that the caracter $a$ is a prefix of a word in $\lang{r_2}$.
%                            \item
%                                $Star \, r_1$: 
%                                We have that $w \in \lang{r_1^*}$ if and only if 
%                                \todo{Fix one def. of *}
%                                \[
%                                    \, \exists n. \, \exists v_1 .. v_n. \, w \, = \, v_1 \cdot .. \cdot v_n 
%                                    \wedge \forall i. \, 1 \leq i \leq n 
%                                    \Rightarrow
%                                    \, v_i \in \lang{r_1}.
%                                \]
%                        \end{enumerate}
                        \todo{Proof}
                    \end{proof}

                \paragraph{} 
                    Given the defining property of derivatives, we can easily see that a generalization of $der$ to words suffices to decide language membership. We only need to check if the derivative w.r.t. to a given word accepts the empty word.

                \code{regexp_mem_der}{}{regexp_mem_der}

                \begin{theorem}
                    \label{mem_der_correct} 
                    The language of a regular expression $r$ is decidable, i.e.
                    \[
                        w \in \lang{r} \Leftrightarrow \varepsilon \in \lang{mem\_der \, r \, w}.
                    \]
                \end{theorem}
                \begin{proof}
                    \todo{Proof}.
                \end{proof}

            

    \chapter{Finite Automata}
        \paragraph{} 
        Another way of characterizing regular languages are finite automata. 
        We will show that the languages of finite automata are exactly $REG$. 
        Furthermore, we will also derive a decision procedure for equivalence of regular expressions.

        \section{Definition}
            A finite automaton consists of
            \begin{enumerate}
                \item
                    finite set of states $Q$, 
                \item 
                    an alphabet $\Sigma$, 
                \item 
                    a starting state $s_0 \in Q$, 
                \item 
                    a set of final states $F \subseteq Q$ 
                \item 
                    and a state-transition relation $\delta$. \cite{DBLP:books/daglib/0011126}
            \end{enumerate}

                We define a \textbf{run} of a word $w \in \Sigma^*$ on an automaton $A = (\Sigma, Q, s_0, F, \delta)$ as any sequence of states $\sigma$ such that 
                $\forall \, 0 <= i < \vert\sigma\vert-2. \, (\sigma_i, w_i, \sigma_{i-1}) \in \delta$.
            A word $w$ is \textbf{accepted} by $A$ if and only if there exists a run $\sigma$ of $w$ on $A$ such that $\sigma_0 = s_0 \, \wedge \, \sigma_{\vert\sigma\vert-1} \in F$.
            The \textbf{language} of $A$ is exactly the set of words accepted by $A$ and is denoted $\lang{A}$. 
            It will later be useful to also have a acceptance criterion defined by runs starting in a given state $x \in Q$, for which we will denote the resulting language $\acc{x}{A}$.

            \subsection{Determinism and Non-Determinism}
                \paragraph{} 
                Finite automata can be non-deterministic in the sense that there exist multiple distinct runs for a word. This is the case if and only if $\delta$ is not functional. 

                \code{nfa}{Non-Deterministic Finite Automata}{automata_nfa}
                \code{nfa_lpath}{}{automata_nfa_lpath}


                For functional $\delta$, we speak of \textbf{deterministic finite automata}. In this case, we also assume $\delta$ to be total and write it as a function. 
                This allows us to directly define the acceptance criterion in terms of the unique run of a word on the automaton. 

                \code{dfa}{Deterministic Finite Automata}{automata_dfa}
                \code{dfa_run}{}{automata_dfa_run'}

                \subsubsection{Equivalence between DFA and NFA}
                    \paragraph{} 
                        Deterministic and non-deterministic finite automata are equally powerful. 
                        One direction is trivial since every DFA is also a NFA. 
                        We prove the other direction using the powerset construction. 
                        Given NFA $A$, we construct an equivalent DFA $A_{det}$ in the following way:
                        The new set of states is the powerset of the given NFA's set of states. 
                        The new starting state is the singleton set containing the original starting state. 
                        A state is final if and only if it contains an original final state. 
                        The transition function on powerset states is defined as follows:
                        \[
                            (P, a, Q) \in \delta_{det} \Longleftrightarrow Q = \bigcup \limits _{p \in P} \{ q | (p,a,q) \in \delta \}.
                        \]


                    \code{powerset_state}{Powerset Construction}{automata_powerset_state}
                    \vspace{-0.4cm}
                    \code{}{}{automata_powerset_s0}
                    \vspace{-0.4cm}
                    \code{}{}{automata_nfa_to_dfa}

                    \begin{theorem}
                        The powerset automaton $A_{det}$ accepts the same language as $A$, i.e.
                        \[
                            \lang{A} = \lang{A_{det}}.
                        \]
                    \end{theorem}

                    \begin{proof}
                        We first prove that for every powerset state $X$ and every state $x \in X$ we have that $\acc{x}{A} \subseteq \acc{X}{A_{det}}$. 
                        Applying this to $X=\{s_0\}$ yields $\lang{A} \subseteq \lang{A_{det}}$.
                        We then show that for every powerset state $X$ and word $w$ with $w \in \acc{X}{A_{det}}$ there exists a state $x$ such that $x \in X$ and $w \in \acc{x}{A}$. 
                        For $X = \{s_0\}$, this shows $\lang{A_{det}} \subseteq \lang{A}$.
                        Both proofs are done by induction on word.
                    \end{proof}

                    \paragraph{}
                        The formalization of this proof is straight-forward and follows exactly the plan laid out above. 
                        The corresponding Lemmas are:
                        \code{powerset_complete}{}{automata_nfa_to_dfa_complete_head}
                        \vspace{-0.4cm}
                        \code{powerset_sound}{}{automata_nfa_to_dfa_sound_head}
                        \vspace{-0.4cm}
                        \code{powerset_correct}{}{automata_nfa_to_dfa_correct_head}
                        

        \section{Connected Components}
            \paragraph{} 
                Finite automaton can have isolated subsets of states that are not reachable from the starting state. 
                These states can not contribute to the language of the automaton. 
                It will later be useful to have automata that only contain reachable states. 
                We define a procedure to extract the connected component from a given automaton.

            \begin{theorem}
                \label{ConnectedAutomaton}
                The language of the connected automaton $A_c$ is identical to that of the original automaton $A$, i.e.
                \[
                    \lang{A} = \lang{A_c}.
                \]
            \end{theorem}
            
            \begin{proof}
                By definition, unreachable states have no influence on the language of an automaton because there is no run from the starting state that contains such a state.
            \end{proof}

            \paragraph{}
                We make use of \ssreflect's $connect$ predicate to extract a sequence of all states reachable from $s_0$. 
                From this, we construct a finite type and use that as the new set of states. 
                These new states carry a proof of reachability.
                We also have to construct a new transition function that ensures transitions always end in reachable states.
                Theorem \ref{ConnectedAutomaton} is trivially solved by induction on word.

                \todo{Add implementation}

        \section{Emptiness}
            \paragraph{}
                Given an automaton $A$, we can check if $\lang{A} = \emptyset$. We simply obtain the connected automaton of $A$ and check if there are any final states left. 
                \begin{theorem} We can decide emptiness of $\lang{A}$ by computing the cardinality of $A_c$'s set of final states, i.e.
                    \label{AutomatonEmpty}
                    \[
                        F_c = \emptyset \Longleftrightarrow \lang{A} = \emptyset.
                    \]
                \end{theorem}

            \begin{proof}
                This is correct since $F_c = \emptyset \Leftrightarrow \lang{A_c} = \emptyset$ and $\lang{A_c} = \lang{A}$ by theorem \ref{ConnectedAutomaton}.
            \end{proof}

                \todo{Add implementation}

        \section{Deciding Equivalence of Finite Automata}
            Given finite automata $A_1$ and $A_2$, we construct DFA $A$ such that the language of $A$ is the symmetric difference of the languages of $A_1$ and $A_2$, i.e.,
            \[ 
                \lang{A} = \lang{A_1} \ominus \lang{A_2} = \lang{A_1} \cap \neg \lang{A_2} \cup \lang{A_2} \cap \neg \lang{A_1}.
            \]
            \begin{theorem} The equivalence of $A_1$ and $A_2$ is decidable, i.e.
                \[
                    \lang{A_1} = \lang{A_2} \mbox{ if and only if } \lang{A} \mbox{ is empty. }
                \]
            \end{theorem}
            \begin{proof}
                The correctness of this procedure follows from the properties of the symmetric difference operator, i.e.
                \[ 
                    \lang{A_1} \ominus \lang{A_2} = \emptyset \Leftrightarrow \lang{A_1} = \lang{A_2}.
                \]
                The decidability of this procedure follows directly from theorem \ref{AutomatonEmpty}.
            \end{proof}

            \todo{Add implementation}
            
        \section{Regular Expressions and Finite Automata}

            \paragraph{} 
                We prove that there is a finite automaton for every extended regular expression and vice versa. 
                In fact, we can give a standard regular expression for every finite automaton.
                With this, we will prove that extended regular expressions are equivalent to standard regular expressions, 
                thereby proving closure under intersection and negation.
                

            \subsection{Regular Expressions to Finite Automata}

                \paragraph{} 
                    We prove that there exists an equivalent automaton for every extended regular expressions.
                    The structure of this proof is given by the inductive nature of regular expressions.
                    For every constructor, we provide an equivalent automaton.

                    \todo{Include all proofs?}

            \subsection{Deciding Equivalence of Regular Expressions}

                \paragraph{} 
                    Based on our procedure to construct an equivalent automaton from a regular expression, we can decide equivalence of regular expressions. Given $r_1$ and $r_2$, we construct equivalent DFA $A_1$ and $A_2$ as above.
                    

            \subsection{Finite Automata to Regular Expressions}
                \paragraph{}
                    We prove that there is an equivalent standard regular expression for every finite automaton.

                
                \paragraph{}
                    Since we are given an automaton it is not obvious how to partition our proof obligations into smaller parts.
                    We use Kleene's original proof, the transitive closure method. 
                    This method recursively constructs a regular expression that is equivalent to the given automaton.
                    Given a DFA $A$, we first assign some ordering to its states. We then define $R^k_{i,j}$ such that 
                    $\lang{R^k_{i,j}}$ is the set of all words that have a run on $A$ starting in state $i$ that ends in state $j$ without ever leaving a state smaller than $k$. 
                    The base case $R^{0}_{i,j}$ is the set of all singleton words that are edges between state $i$ and $j$, and $\varepsilon$ if $i=j$. 
                    Given $R^k_{i,j}$ we can easily define $R^{k+1}_{i,j}$ based on the observation that only one new state has to be considered:
                    \todo{Insert complete formal definition}
                    \[
                        R^{k+1}_{i,j} = R^{k}_{i,k} \cdot (R^{k}_{k,k})^* \cdot R^{k}_{k,j} + R^{k}_{i,j}.
                    \]
                    \paragraph{}
                        We make use of \ssreflect's ordinals to get an ordering on states. 
                        We chose to employ ordinals for $i$ and $j$, but not for $k$. 
                        This simplifies the inductive definitions on $k$. 
                        It does, however, lead to explicit conversions when $k$ is used in place of $i$ or $j$.
                        In fact, $i$ and $j$ are states in our \coq\ implementation. 
                        We only rely on ordinals for comparison to $k$.
                        \todo{Add implementation of $R$}
                    \paragraph{}
                        Furthermore, we define $L^k_{i,j} \subseteq \lang{A}$ in terms of runs on the automaton. 
                        The relation of $L^k_{i,j}$ to $\lang{A}$ can be proven very easily.
                        We will also prove it equivalent to $R^k_{i,j}$.
                        This allows us to connect $R^k_{i,j}$ to $\lang{A}$.
                        \code{tc_allbutlast}{}{transitive_closure_allbutlast}
                        \vspace{-0.3cm} 
                        \code{tc_L}{}{transitive_closure_L}
                    
                    \begin{theorem} We can express $\lang{A}$ in terms of $L$. $L$ is equivalent to $R$.
                        \label{LR}
                        \[
                             \lang{A} = \bigcup\limits_{f \in F} L^{|Q|}_{s_0, f} = \lang{\sum\limits_{f \in F} R^{|Q|}_{s_0, f}}.
                        \]
                    \end{theorem}

                    \begin{proof}
                        By definition, every $w \in \lang{A}$ has a run that ends in some $f \in F$. 
                        Then, by definition, $w \in  L^{|Q|}_{s_0, f}$. 

                    \paragraph{}
                        It remains to show that $\lang{R^k_{i,j}} = L^k_{i.j}$. 
                        This claim can be proven by induction over $k$. 
                        We begin with the inclusion of $\lang{R^k_{i,j}}$ in $L^k_{i,j}$. 
                        For $k=0$, we do a case distinction on $i==j$ and unfold $R$. 
                        The resulting three cases ($i==j \wedge w=\varepsilon$, $i==j \wedge |w|=1$, $i<>j \wedge |w|=1$) are easily closed. 

                        The inductive step has two cases: A triple concatenation and a simple recursion. 
                        The second case is solved by the inductive hypothesis.
                        In the firs case, we split up the concatenation such that
                        \[
                            w = w_1 \cdot w_2 \cdot w_3 
                            \wedge w_1 \in \lang{R^k_{i,k}} 
                            \wedge w_2 \in \lang{(R^k_{k,k})^*} 
                            \wedge w_3 \in \lang{R^k_{k,j}}.
                        \]
                    \paragraph{}
                        The induction hypothesis is applied to $w_1$ and $w_3$ to get $w_1 \in L^k_{i,k}$ and $w_3 \in L^k_{k,j}$.
                        We use a lemma by Coquand and Siles that splits $w_2$ into a sequence of words from $\lang{R^k_{k,k}}$ to which we can apply the induction hypothesis. 
                        Two concatenation lemmas for $L$ are used to merge the sequence of words proven to be in $L^k_{k,k}$,
                        $w_1$ and $w_3$. This shows $\lang{R^k_{i,j}} \subseteq L^k_{i,j}$.

                        \paragraph{}
                            Next, we show the inclusion of $L^k_{i,j}$ in $\lang{R^k_{i,j}}$, again by induction over k. 
                            The base case is solved by case distinction on $i==j$. 
                            The inductive step requires a \textbf{splitting lemma} for $L$ which shows that every non-empty word in $L^{k+1}_{i,j}$ is either in $L^k_{i,j}$ or has a non-empty prefix in $L^k_{i,k}$ and a corresponding suffix in $L^{k+1}_{k,j}$.
                            The 
                            In the first case, we can apply the induction hypothesis. 
                            In the second case, we use size induction on the word, apply the original induction hypothesis to the prefix and the size induction hypothesis to the suffix. 
                            We use two concatenation lemmas for $R$ to merge the sub-expression. 
                            This finishes the proof.
                        \end{proof}
                            
                        \paragraph{}
                            Formalizing theorem \ref{LR} requires infrastructure to deal with $allbutlast$. 
                            Once this is in place, we can formalize the concatenation lemmas for $R$ and $L$.
                            These are required later to connect sub-results. 
                            
                            \code{tc_RcatL}{}{transitive_closure_R_catL_head}
                            \code{tc_LcatL}{}{transitive_closure_L_catL_head}
                            \code{tc_LcatR}{}{transitive_closure_L_catL_head}

                        \paragraph{}
                            We also need the splitting lemma mentioned earlier.
                            This is quite intricate. We could split right after the first character and thereby simplify the lemma. 
                            However, the current form has the advantage of requiring simple concatenation lemmas.

                            \code{tc_split}{}{transitive_closure_L_split_head}

                        \paragraph{}
                            These lemmas suffice to show the claim of theorem \ref{LR}.
                            \code{tc_RL*}{}{transitive_closure_R_L_star_head}
                            \code{tc_RL}{}{transitive_closure_R_L_head}
                            \code{tc_LR1}{}{transitive_closure_L_R_1_head}
                            \code{tc_LR}{}{transitive_closure_L_R_head}
                            \todo{Fix this mess}
                            

            \paragraph{} 


            

    \chapter{Myhill-Nerode Theorem}

            \section{Definition}

                \todo{Find textbook}

                \paragraph{} Given a language $L$, the Myhill-Nerode relation $\approx_L$ is defined such that 
                \[
                    \forall u, v \in \Sigma^*. \,
                    u \approx_L v \, \Longleftrightarrow \, 
                    \forall w \in \Sigma^*.\, u \cdot w \in L \Leftrightarrow v \cdot w \in L.
                \]

                \code{mn}{Myhill-Nerode relation}{myhill_nerode_MN}

                \begin{theorem}{Myhill-Nerode Theorem.}
                    \label{MN}
                    A language $L$ is regular if and only if $\,\approx_L$ is of finite index.
                \end{theorem}

            \section{Finite Partitionings and Equivalence Classes}

                \paragraph{}
                    \coq\ does not have quotient types. 
                    We pair up functions and proofs for certain properties of those functions to emulate quotient types.

                \paragraph{} 
                    A finite partitioning is a function from $\Sigma^*$ to some finite type $F$. 
                    We use this concept to model equivalent classes in \coq. 
                    A finite partitioning of the Myhill-Nerode relation is a finite partitioning $f$ that also respects the Myhill-Nerode relation, i.e.,
                    \[
                        \forall u, v \in \Sigma^*. \,
                        f(u) = f(v) \Leftrightarrow u \approx_L v.
                    \]
                    

                    \code{mn_rel}{Finite partitioning of the Myhill-Nerode relation}{myhill_nerode_MN_rel}

                    \begin{theorem}
                        $\approx_L$ is of finite index if and only if there exists a finite partitioning of the Myhill-Nerode relation.
                    \end{theorem}

                    \begin{proof}
                        If $\approx_L$ is of finite index, we use the set equivalence classes as a finite type and construct $f$ such that
                        \[
                            \forall w.\, f(w) = [w]_\approx.
                        \]
                        \paragraph{}
                        $f$ is a finite partitioning of the Myhill-Nerode relation by definition.

                        \paragraph{}
                        Conversely, if we have a finite partitioning of the Myhill-Nerode relation, we can easily see that $\approx_L$ must be of finite index since $f$'s values directly correspond to equivalence classes. The image of $f$ is finite. Therefore, $\approx_L$ is of finite index.
                    \end{proof}

                \paragraph{}

                    A more general concept is that of a refining finite partitioning of the Myhill-Nerode relation:
                    \[
                        \forall u, v \in \Sigma^*. \,
                        f(u) = f(v) \Rightarrow u \approx_L v.
                    \]

                    \code{mn_ref}{Refining finite partitioning of the Myhill-Nerode relation}{myhill_nerode_MN_ref}



                \paragraph{}
                    We require all partitionings to be surjective.
                    Therefore, every equivalence class $x$ has at least one class representative which we denote $\crep{x}$.
                    Mathematically, this is not a restriction since there are no empty equivalence classes.
                    In our constructive setting we would have to give a procedure that builds a minimal finite type $F'$ from $F$ and a corresponding function $f'$ from $\Sigma^*$ to $F'$ such that $f'$ is surjective and extensionally equal to $f$.

        \section{Minimizing Equivalence Classes}

            \paragraph{}
                We will prove that refining finite partitionings can be converted into finite partitionings. 
                For this purpose, we employ the table-filling algorithm to find indistinguishable states under the Myhill-Nerode relation (\cite{DBLP:books/daglib/0011126}).
                However, we do not rely on an automaton. 
                In fact, we use the finite type $F$, i.e., the equivalence classes, instead of states.

            \paragraph{}
                Given a refining finite partitioning $f$, we construct a fixed-point algorithm.
                The algorithm initially outputs the set of equivalence classes that are distinguishable by the inclusion of their class representative in $L$. 
                We denote this initial set $dist_0$.
                \[
                    dist_0 := \{ (x,y)  \in F \times F \, | \, \crep{x} \in L \Leftrightarrow \crep{y} \notin L\}.
                \]
                
            \paragraph{}
                To find more distinguishable equivalence classes, we have to identify equivalence classes that lead to distinguishable equivalence classes. 
                \begin{definition}
                    We say that a pair of equivalence classes $(x,y)$ \textbf{transitions} to $(x', y')$ with $a$ if and only if
                    \[
                        f (\crep{x}\cdot a) = x' \wedge f (\crep{y} \cdot a) = y'.
                    \]
                    We denote $(x', y')$ by $ext_a(x,y)$.
                \end{definition}

                The fixed-point algorithm tries to extend the set of distinguishable equivalence classes by looking for a so-far undistinguishable pair of equivalence classes that transitions to a pair of distinguishable equivalence classes.

                \begin{definition}
                    \[
                        unnamed(dist) := dist_0 \cup dist \cup \{ (x,y) \, | \, \exists a. \, ext_a(x,y) \in dist\}
                    \]
                \end{definition}

                \begin{lemma}
                    \label{dist_monotone}
                    $unnamed$ is monotone and has a fixed-point.
                \end{lemma}
                \begin{proof}
                    Monotonicity follows directly from the monotonicity of $\cup$. 
                    The number of sets in $F \times F$ is finite. 
                    Therefore, $unnamed$ has a fixed point.

                \end{proof}
                \paragraph{}
                    Let \textit{\textbf{distinct}} be the fixed point of $unnamed$.
                    Let \textit{\textbf{equiv}} be the complement of $distinct$.
                    \todo{Finish construction}
                    \begin{theorem}
                        \label{MN_MIN}
                        $f_min$ is a finite partitioning of the Myhill-Nerode relation on $L$.
                    \end{theorem}

                \todo{Add formalization}



        \section{Finite Automata and Myhill-Nerode}

            \paragraph{}
                We prove theorem \ref{MN} by proving it equivalent to the existence of an automaton that accepts $L$.
                

            
            \subsection{Finite Automata to Myhill-Nerode}
                \paragraph{}
                    Given DFA $A$, for all words $w$ we define $f(w)$ to be the last state of the run of $w$ on $A$.

                \begin{lemma} 
                    \label{DFA_MN_F}
                    $f$ is a refining finite partitioning of the Myhill-Nerode relation on $\lang{A}$. 
                \end{lemma} 
                \begin{proof} 
                    The set of states of $A$ is finite.
                    For all $u, v$ and $w$ we that if $f(u) = f(v) = x$, i.e.,
                    the runs of $u$ and $v$ on $A$ end in the exact same state $x$.
                    From this, we get that for all $w$, runs of $u \cdot w$ and $v \cdot w$ on $A$ also end in the same state.
                    Therefore, $u\cdot w \in \lang{A}$ if and only if $v \cdot w \in \lang{A}$.
                \end{proof}

                \begin{theorem}
                    If $L$ is accepted by DFA $A$, then there exists a finite partitioning of the Myhill-Nerode relation on $L$.
                \end{theorem}
                \begin{proof}
                    From lemma \ref{DFA_MN_F} we get a refining finite partitioning $f$ of the Myhill-Nerode relation on $\lang{A}$. 
                    Since $L$ is accepted by $A$, $L = \lang{A}$. 
                    Therefore, $f$ is a refining finite partitioning of the Myhill-Nerode relation on $L$.
                    By theorem \ref{MN_MIN} there also exists a finite partition of the Myhill-Nerode relation on $L$.
                \end{proof}


            \subsection{Myhill-Nerode to Finite Automata}

                \paragraph{}


    \chapter{Conclusion}

    \chapter{References}

    \nocite{*}

    \bibliography{bib}{}
    \bibliographystyle{plain}

\end{document}
