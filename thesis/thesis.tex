\documentclass[11pt,a4paper,oneside]{book}

\input{includes.tex}
\input{macros.tex}


\title{Constructive Formalization of Regular Languages}
\author{Jan-Oliver Kaiser}

\begin{document}
    \maketitle
    \tableofcontents
    
    \chapter{Introduction}

        \paragraph{} 
            We aim to show that an extensive, yet elegant formalization of regular languages can be achieved in constructive type theory.

        \section{Recent work}
        
            \paragraph{} 
                There have been many publications on regular languages in recent years. Many of them investigate decidability of equivalence of regular languages, though there have also been new equivalence proofs regarding different characterizations of regular languages.

    \chapter{Coq, \ssreflect}

        \paragraph{}
            We decided to employ the Small Scale Reflection Extension (\textbf{\ssreflect}) for the \textbf{\coq} proof assistant. 
            The most important factors in this decision were \ssreflect's excellent support for finite types, list operations and graphs. \ssreflect{} also introduces many syntactic extensions that can often be used to shorten the bookkeeping overhead of proofs considerably.

    \chapter{Decidable Languages}

    \section{Definition}
        \paragraph{}
        We closely follow the definitions from \cite{DBLP:books/daglib/0011126}.
        An \textbf{alphabet} $\Sigma$ is finite, nonempty a set of symbols. 
        A \textbf{word} $w$ is a finite sequence of symbols chosen from some alphabet. 
        We use $|w|$ to denote the \textbf{length} of a word $w$. 
        We definte $\Sigma^k$ to be the \textbf{set of words of length k}.
        The \textbf{set of all words} over an alphabet $\Sigma$ is denoted $\Sigma^*$, i.e. $\Sigma^* = \bigcup_{k \in \mathbb{N}} \Sigma^k$.
        \todo{Define Kleene star}%
        The following operations will be used on languages: Kleene star, concatenation ($L_1 \cdot L_2 := \{w \cdot v\ \vert w \in L_1,  \in L_2\}$), and the boolean operations ($\cup$, $\cap$, $\neg$) on languages.

        
        \paragraph{} We restrict all further discussion to \textbf{decidable languages}:
        \[
            \mathcal{L}_{dec} := \{ \, L \, \subseteq \, \Sigma^* \, 
                \vert \, \exists f. \, \forall x \in \Sigma^*. \, f(x) = 1 \Leftrightarrow  x \in L. \}
        \] 

        \paragraph{Observation} 
            The decidable languages are closed under $\cdot, \,^*, \cup, \cap$ and $\neg$. 
            For $\cdot$ and $\,^*$, this is easily seen by considering nonempty substrings, of which there are finitely many. 
            The boolean operations can be applied directly to the decision functions.

        \paragraph{} 
            We formalize decidable languages as functions from word to $\mathbb{B}$.
            \code{language}{}{misc_language}

        \section{Regular Languages}
        
        %\paragraph{} In our formalization, we consider three well-known characterizations of regular languages: \textbf{Regular expressions} (due to Stephen Cole Kleene \cite{KleeneNets}), \textbf{finite automata}, and the characterization derived from the \textbf{Myhill-Nerode theorem} (John Myhill, Anil Nerode \cite{Nerode1958}) 
    
            \paragraph{}
            The set of regular languages $REG$ is defined to be exactly those languages generated by the following inductive definition.
            \begin{itemize}
                \item
                    $\emptyset \in REG$, 
                \item
                    $\forall a \in \Sigma. \, \{a\} \in REG$, 
                \item
                    $\forall L_1, L_2 \in REG. \, L_1^* \in REG, \, L_1 \cup L_2 \in REG, \, L_1 \cdot L_2 \in REG$.
            \end{itemize}

            \paragraph{Observation} $REG$ is closed under $\neg$ and $\cap$. \todo{Sketch proof.}


        \subsection{Regular Expressions}

                \paragraph{} 
                Regular expressions mirror the definition of regular languages very closely. We will consider extended regular expressions that include $\neg$, $\cap$ and $.$, which is a single-symbol wildcard. 
                %Regular expressions are finite expressions over an alphabet consisting of atomic expressions or subexpressions combined by operators. Every regular expressions has an associated language, either directly or by some combination of the subexpressions' languages.
                We take the implementation from Coquand and Siles's development (\cite{DBLP:conf/cpp/CoquandS11}), which is also based on \ssreflect and comes with helpful infrastructure for our proofs.

                \code{regexp}{Regular Expressions}{regexp_regular_expression}

                \subsection{Computing Language Membership}
                    \paragraph{}
                We make use of \textbf{derivatives of regular expressions} (\cite{DBLP:journals/jacm/Brzozowski64}) to compute if a word $w \in \Sigma^*$ is contained in the language $\lang{r}$ of the regular expression $r$. Derivatives are themselves regular expressions and are computed in respect to a single input character. The derivative $der \,  a \, r$ of $r$ w.r.t. to $a$ is defined such that 
                \[
                    \forall w \in \Sigma^*. \, w \, \in \, \lang{der \, a \, r} \Leftrightarrow a\cdot w \, \in \, \lang{r}.
                \]
                A suitable implementation is provided by Coquand and Siles.

                \code{regexp_der}{Derivatives of Regular Expressions}{regexp_der}

                \paragraph{} 
                    Given the defining property of derivatives, we can easily see that a generalization of $der$ to words suffices to compute membership. We only need to check if the derivative w.r.t. to a given word accepts the empty word.

                %\code{regexp_wder}{}{regexp_wder}
                %\vspace{-0.4cm}
                \code{regexp_mem_der}{}{regexp_mem_der}

            

    \chapter{Finite Automata}
        \paragraph{} 
        Another way of characterizing regular languages are finite automata. 
        We will show that the languages of finite automata are exactly $REG$. 
        Furhtermore, we will also derive a decision procedure for equivalence of regualar expressions.

        \section{Definition}
            A finite automaton consists of a 
            \begin{enumerate}
                \item
                    finite set of states $Q$, 
                \item 
                    an alphabet $\Sigma$, 
                \item 
                    a starting state $s_0 \in Q$, 
                \item 
                    a set of final states $F \subseteq Q$ 
                \item 
                    and a state-transition relation $\delta$. 
            \end{enumerate}

                We define a \textbf{run} of a word $w \in \Sigma^*$ on an automaton $A = (\Sigma, Q, s_0, F, \delta)$ as any sequence of states $\sigma$ such that $\forall i < \vert\sigma\vert-1. \, (\sigma_i, w_i, \sigma_{i+1}) \in \delta$.
            A word is \textbf{accepted} by an automaton if and only if there exists a run $\sigma$ such that $\sigma_0 = s_0 \, \wedge \, \sigma_{\vert\sigma\vert-1} \in F$. 
            The \textbf{language} $\lang{A}$ of an automaton is exactly the set of accepted words. It will later be useful to also have a notion of acceptance starting in any state $x \in Q$, for which we will denote the resulting language as by $\acc{x}{A}$.

            \subsection{Determinism and Non-Determinism}
                \paragraph{} 
                Finite automata can be non-deterministic in the sense that there exist multiple distinct runs for a word. This is the case if and only if $\delta$ is not functional. 
                %Our implementation very much mirrors the mathematical definition.

                \code{nfa}{Non-Deterministic Finite Automata}{automata_nfa}
                %\code{nfa_accept}{}{automata_nfa_accept}
                %\code{nfa_lang}{}{automata_nfa_lang}
                \code{nfa_lpath}{}{automata_nfa_lpath}

                %\code{nfa_lpath}{}{automata_nfa_lpath}

                For functional $\delta$, we speak of \textbf{deterministic finite automata}. In this case, we also assume $\delta$ to be total so that we can write it as a function. 
                This allows us to directly define the acceptance criterion. 

                \code{dfa}{Deterministic Finite Automata}{automata_dfa}
                %\code{dfa_accept}{}{automata_dfa_accept}
                %\code{dfa_lang}{}{automata_dfa_lang}
                \code{dfa_run}{}{automata_dfa_run'}

                \subsubsection{Equivalence between DFA and NFA}
                    \paragraph{} 
                        Deterministic and non-deterministic finite automata are both equally powerful. 
                        One direction is trivial since every DFA is also a NFA. 
                        We prove the other direction using the powerset construction. 
                        Given NFA $A$, we construct an equivalent DFA $A_{det}$ in the following way:
                        The new set of states is the powerset of the given NFA's set of states. 
                        The new starting state is the singleton set containing the original starting state. 
                        A state is final if and only if it contains an original final state. 
                        Transitions are done for every original state contained in the new state, i.e. 
                        \[
                            (P, a, Q) \in \delta_{det} \Longleftrightarrow Q = \bigcup \limits _{p \in P} \{ q | (p,a,q) \in \delta \}.
                        \]


                    \code{powerset_state}{Powerset Construction}{automata_powerset_state}
                    \vspace{-0.4cm}
                    \code{}{}{automata_powerset_s0}
                    \vspace{-0.4cm}
                    \code{}{}{automata_nfa_to_dfa}

                    \paragraph{}
                        We want to prove that the powerset automaton $A_{det}$ accepts the same language as $A$, i.e.
                        \[
                            \lang{A} = \lang{A_{det}}.
                        \]


                    \paragraph{}
                        We first prove that for every powerset state $X$ and every state $x \in X$ we have that $\acc{x}{A} \subseteq \acc{X}{A_{det}}$. 
                        Applying this to $X=\{s_0\}$ yields $\lang{A} \subseteq \lang{A_{det}}$.
                        We then show that for every powerset state $X$ and word $w$ with $w \in \acc{X}{A_{det}}$ there exists a state $x$ such that $x \in X$ and $w \in \acc{x}{A}$. 
                        For $X = \{s_0\}$, this shows $\lang{A_{det}} \subseteq \lang{A}$.
                        Both proofs are done by induction on word.

                    \paragraph{}
                        The formalization of this proof is straight-forward and follows exactly the plan laid out above. 
                        The corresponding Lemmas are:
                        \code{powerset_correct1}{}{automata_nfa_to_dfa_correct1_head}
                        \vspace{-0.4cm}
                        \code{powerset_correct2}{}{automata_nfa_to_dfa_correct2_head}
                        \vspace{-0.4cm}
                        \code{powerset_correct}{}{automata_nfa_to_dfa_correct_head}
                        

        \section{Connected Components}
            \paragraph{} 
                Finite automaton can have isolated subsets of states that are not reachable from the starting state. 
                These states can not contribute to the language of the automaton. 
                It will later be useful to have automata that only contain reachable states. 
                We define a procedure to extract the connected component from a given automaton.

            \begin{theorem}
                The language of the connected automaton $A_c$ is identical to that of the original automaton $A$, i.e.
                \[
                    \lang{A} = \lang{A_c}.
                \]
            \end{theorem}
            
            \paragraph{}
                By definition, unreachable states have no influence on the language of an automaton because there is no run from the starting state that contains such a state.

            \paragraph{}
                We make use of \ssreflect's $connect$ predicate to extract a sequence of all states reachable from $s_0$. 
                From this, we construct a finType and use that as the new set of states.


        \section{Emptiness}
            \paragraph{}
                Given an automaton $A$, we can now check if $\lang{A} = \emptyset$. We simply obtain the connected automaton $A_c$ of $A$ and compute $F_c \stackrel{?}{=} \emptyset$. This is correct because $F_c = \emptyset \Leftrightarrow \lang{A_c} = \emptyset$ and $\lang{A_c} = \lang{A}$.

        \section{Regular Expressions and Finite Automata}

            \paragraph{} 
                We proof that there is a finite automaton for every regular expression and vice versa. 

            \subsection{Regular Expressions to Finite Automata}

                \paragraph{} 
                    We give an equivalent automaton for every single constructor of regular expressions.
                    Out of those proofs, only .... are interesting.

            \subsection{Deciding Equivalence of Regular Expressions}

                \paragraph{} 
                    Based on our procedure to build an equivalent automaton from a regular expression, we can now decide equivalence of regular expressions. Given $r_1$ and $r_2$, we construct equivalent DFA $A_1$ and $A_2$ as above.
                    Next, we construct DFA $A$ such that the language of $A$ is the symmetric difference of the languages of $A_1$ and $A_2$, i.e. 
                    \[ \lang{A} = \lang{A_1} \ominus \lang{A_2} = \lang{A_1} \cap \neg \lang{A_2} \cup \lang{A_2} \cap \neg \lang{A_1}.
                    \] 
                    We then check for emptiness of $A$. The correctness of this procedure follows directly from 
                    \[ 
                        \lang{A_1} \ominus \lang{A_2} = \emptyset \Leftrightarrow \lang{A_1} = \lang{A_2}.
                    \]
                    

            \subsection{Finite Automata to Regular Expressions}
                
                \paragraph{}
                    Since we are given only an automaton it is not obvious how to partition our proof obligations into smaller parts.
                    We use Kleene's original proof, the transitive closure method. 
                    This method recursively builds a regular expression that is equivalent to the given automaton.
                    Given a DFA $A$, we first assign some ordering to it's states. We then define $R^k_{i,j}$ such that 
                    $\lang{R^k_{i,j}}$ is the set of all words that have a run on $A$ starting in state $i$ that ends in state $j$ without ever leaving a state smaller than $k$. Given $R^k_{i,j}$ we can easily define $R^{k+1}_{i,j}$ based on the observation that only one new state has to be considered:
                    \[
                        R^{k+1}_{i,j} = R^{k}_{i,k} \cdot (R^{k}_{k,k})^* \cdot R^{k}_{k,j} + R^{k}_{i,j}.
                    \]
                    \paragraph{}
                        The base case $R^{0}_{i,j}$ is then simply the set of all singleton words that are edges between state $i$ and $j$, and $\varepsilon$ if $i=j$. 
                        We make use of \ssreflect's ordinals to get an ordering on states. 
                        Furthermore, we define $L^k_{i,j} \subseteq \lang{A}$ in terms of runs on the automaton. 
                        \code{tc_allbutlast}{}{transitive_closure_allbutlast}
                        \vspace{-0.3cm} 
                        \code{tc_L}{}{transitive_closure_L}
                    
                    \paragraph{}
                        \begin{theorem} 
                        \[
                            \lang{\sum\limits_{f \in F} R^{|Q|}_{s_0, f}} = \bigcup\limits_{f \in F} L^{|Q|}_{s_0, f} = \lang{A}.
                        \]
                        \end{theorem}
                        For this, we first show $\lang{R^k_{i,j}} = L^k_{i.j}$. 
                        In contrast to the previous claim, this one can be proven by induction over $k$. 
                        We begin with the inclusion of $\lang{R^k_{i,j}}$ in $L^k_{i,j}$. 
                        For $k=0$, we do a case distinction on $i==j$ and unfold $R$. 
                        The resulting three cases ($i==j \wedge w=\varepsilon$, $i==j \wedge |w|=1$, $i<>j \wedge |w|=1$) are easily closed. 

                        The inductive step has two cases: A triple concatenation and a simple recursion. 
                        The second case is solved by the inductive hypothesis.
                        In the firs case, we split up the concatenation such that
                        \[
                            w = w_1 \cdot w_2 \cdot w_3 
                            \wedge w_1 \in \lang{R^k_{i,k}} 
                            \wedge w_2 \in \lang{(R^k_{k,k})^*} 
                            \wedge w_3 \in \lang{R^k_{k,j}}.
                        \]
                        The induction hypothesis is then applied to $w_1$ and $w_3$ to get $w_1 \in L^k_{i,k}$ and $w_3 \in L^k_{k,j}$.
                        We then use a lemma by Coquand and Sile that splits $w_2$ into a sequence of words from $\lang{R^k_{k,k}}$ to which we can then apply the induction hypothesis. 
                        Two concatenation lemmas for $L$ are used to merge the sequence of words now proven to be in $L^k_{k,k}$,
                        $w_1$ and $w_3$. This shows $\lang{R^k_{i,j}} \subseteq L^k_{i,j}$.

                        \paragraph{}
                            Next, we show the inclusion of $L^k_{i,j}$ in $\lang{R^k_{i,j}}$, again by induction over k. 
                            The base case is solved by case distinction on $i==j$. 
                            The inductive step requires a splitting lemma for $L$ which shows that every non-empty word in $L^{k+1}_{i,j}$ is either in $L^k_{i,j}$ or has a non-empty prefix in $L^k_{i,k}$ and a corresponding suffix in $L^{k+1}_{k,j}$. 
                            In the first case, we can apply the induction hypothesis. 
                            In the second case, we use size induction on the word, apply the original induction hypothesis to the prefix and the size induction hypothesis to the suffix. 
                            We use two concatenation lemmas for $R$ to merge the sub-expression. 
                            This finishes the proof.
                            

            \paragraph{} 


            

        \chapter{Myhill-Nerode Theorem}

            \section{Definition}

                \paragraph{} Given a language $L$, the Myhill-Nerode relation $\approx_L$ is defined such that 
                \[
                    \forall u, v \in \Sigma^*. \,
                    u \approx_L v \, \Longleftrightarrow \, 
                    \forall w \in \Sigma^*.\, u \cdot w \in L \Leftrightarrow v \cdot w \in L.
                \]

                \code{mn}{Myhill-Nerode relation}{myhill_nerode_MN}

                The Myhill-Nerode thereom states that, given a language $L$,
                \[
                    L \in REG \, \Longleftrightarrow \, \approx_L \mbox{ is of finite index.}
                \]

            \section{Finite Partitionings and Equivalence Classes}

                \paragraph{}
                    \coq does not have quotient types. 
                    We pair up functions and proofs for certain properties of those functions to emulate quotient types.

                \paragraph{} 
                    A finite partitioning is a function from $\Sigma^*$ to some finite type $F$. 
                    We use this concept to model equivalent classes in \coq. 
                    A finite partitioning of the Myhill-Nerode relation is a finite partitioning $f$ that also respects the Myhill-Nerode relation, i.e. 
                    \[
                        \forall u, v \in \Sigma^*. \,
                        f(u) = f(v) \Leftrightarrow u \approx_L v.
                    \]
                    

                    \code{mn_rel}{Finite partitioning of the Myhill-Nerode relation}{myhill_nerode_MN_rel}

                    A more general concept is that of a refining finite partitioning of the Myhill-Nerode relation:
                    \[
                        \forall u, v \in \Sigma^*. \,
                        f(u) = f(v) \Rightarrow u \approx_L v.
                    \]

                    \code{mn_ref}{Refining finite partitioning of the Myhill-Nerode refation}{myhill_nerode_MN_ref}






        \section{Finite Automata and Myhill-Nerode}

            \paragraph{}

            \subsection{Minimizing Equivalence Classes}

                \paragraph{}
            
            \subsection{Finite Automata to Myhill-Nerode}

                \paragraph{}

            \subsection{Myhill-Nerode to Finite Automata}

                \paragraph{}


    \chapter{Conclusion}

    \chapter{References}

    \bibliography{bib}{}
    \bibliographystyle{plain}

\end{document}
